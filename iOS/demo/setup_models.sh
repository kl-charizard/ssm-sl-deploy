#!/bin/bash

# Setup script for iOS Sign Language Detection App
# This script ensures the Core ML models are properly set up

echo "ü§ü Setting up Sign Language Detection iOS App..."

# Check if we're in the right directory
if [ ! -f "demo.xcodeproj/project.pbxproj" ]; then
    echo "‚ùå Error: Please run this script from the iOS/demo directory"
    exit 1
fi

# Check if models exist
if [ ! -f "SignLanguageModel.mlmodel" ] || [ ! -f "SignLanguageModel_optimized.mlmodel" ]; then
    echo "üì• Converting PyTorch model to Core ML..."
    
    # Go to project root
    cd ../../
    
    # Convert model
    python scripts/convert_to_coreml.py \
        --model-path checkpoints/best_model.pth \
        --output-path iOS/demo/SignLanguageModel.mlmodel \
        --optimize
    
    # Go back to iOS demo directory
    cd iOS/demo
fi

echo "‚úÖ Core ML models are ready!"
echo "üì± You can now open demo.xcodeproj in Xcode and build the app"
echo ""
echo "üöÄ Next steps:"
echo "1. Open demo.xcodeproj in Xcode"
echo "2. Select iPhone simulator"
echo "3. Press ‚åò+R to build and run"
echo "4. Grant camera permission when prompted"
